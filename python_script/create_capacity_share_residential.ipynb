{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file creates 'AgentShare' parameters, and integrated it into 'Technodata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfplumber\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the key is the consumption/demand name is MUSE\n",
    "# the value is the name used in the HouseholdElectricitySurveyFinalReportissue4.pdf\n",
    "non_heat_enduses_mapping = {\n",
    "    'RES.COOKING': 'Cooking',\n",
    "    'RES.COOLING': 'Cold appliances',\n",
    "    'RES.CONSUMER-ELECTRONICS.TV': 'Audiovisual',\n",
    "    'RES.LIGHTING': 'Lighting',\n",
    "    'RES.REFRIGERATORS': 'Cold appliances',\n",
    "    'RES.FREEZERS': 'Cold appliances',\n",
    "    'RES.COMPUTERS': 'ICT',\n",
    "    'RES.WET.APPLIANCES': 'Washing/Drying',\n",
    "    'RES.OTHER': 'Other'\n",
    "}\n",
    "\n",
    "heating_enduses_mapping = {\n",
    "    'RES.HOT-WATER': 'Water heating',\n",
    "    'RES.SPACE-HEAT': 'Heating'\n",
    "}\n",
    "non_heat_enduses = list(non_heat_enduses_mapping.keys())\n",
    "heating_enduses = list(heating_enduses_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ofgem data folder\n",
    "data_folder = Path.cwd().parent / \"Ofgem_Archetype\"\n",
    "\n",
    "# save the output files in the MUSE_Files folder\n",
    "output_folder = Path.cwd().parent /  \"Residential\"/ \"MUSE_files\" / \"Ofgem_agents\"\n",
    "\n",
    "# read the tables in the excel file\n",
    "df_ofgem = pd.read_excel(data_folder / \"Ofgem energy consumer archetypes2024_Tables1.xlsx\", sheet_name=\"original\").dropna()\n",
    "\n",
    "# keep only the columns we need\n",
    "col_to_keep = ['Archetype','Average Annual Elec consumption (kWh)','Average Annual Gas consumption (kWh)', 'Main heating Fuel']\n",
    "df_ofgem = df_ofgem[col_to_keep]\n",
    "\n",
    "# display the data\n",
    "df_ofgem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the \"Technodata.csv\" with single agents (which was created in an earlier version)\n",
    "technodata_df = pd.read_csv( Path.cwd().parent /\"Buildings/MUSE_Files\" / \"Technodata.csv\")\n",
    "\n",
    "# Step 1: Identify columns with \"new\" in the \"Unit\" row, a.k.a the Agent columns\n",
    "columns_to_drop = technodata_df.loc[0][technodata_df.loc[0] == \"new\"].index\n",
    "\n",
    "# Step 2: Drop these old Agent columns from the DataFrame\n",
    "technodata_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Step 3: Extract the \"Unit\" row, which will be added back to the DataFrame later\n",
    "unit_row = technodata_df.iloc[[0]]\n",
    "\n",
    "# Step 4: Remove the \"Unit\" row from technodata_df for merging, this is optional since in step 5, the \"Unit\" row will not be included anyway.\n",
    "# technodata_df_no_unit = technodata_df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Step 5: split the df into two dfs based on the \"EndUse\" column\n",
    "# Define the condition for splitting\n",
    "non_heat_use = technodata_df['EndUse'].str.contains('|'.join(non_heat_enduses), case=False, na=False)\n",
    "heating_use = technodata_df['EndUse'].str.contains('|'.join(heating_enduses), case=False, na=False)\n",
    "\n",
    "# Split the DataFrame\n",
    "df_non_heat = technodata_df[non_heat_use]\n",
    "df_heating = technodata_df[heating_use]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Non-heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_non_heat_share import non_heat_capacity_share\n",
    "\n",
    "df1 = non_heat_capacity_share(df_non_heat, df_ofgem,non_heat_enduses_mapping)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) heating enduse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_heating_share import heating_capacity_share\n",
    "df2 = heating_capacity_share(df_heating, df_ofgem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) combine dfs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify newly added columns from enduse_shares_df\n",
    "new_columns = set(df1.columns) - set(unit_row.columns) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify newly added columns from enduse_shares_df\n",
    "new_columns = new_columns = set(df1.columns) - set(unit_row.columns) \n",
    "\n",
    "# Step 2: Update the Unit row\n",
    "unit_row = unit_row.copy()\n",
    "for col in new_columns:\n",
    "    unit_row[col] = 'new'\n",
    "\n",
    "# Step 3: Add the updated Unit row back to the top\n",
    "final_merged_df = pd.concat([unit_row, df1,df2], ignore_index=True)\n",
    "\n",
    "# save the final df\n",
    "final_merged_df.to_csv(output_folder / \"Technodata.csv\", index=False)\n",
    "\n",
    "print(f\"Technodata.csv is successfully saved to {output_folder / 'Technodata.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
